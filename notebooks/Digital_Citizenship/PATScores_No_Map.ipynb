{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["![Callysto.ca Banner](https://github.com/callysto/curriculum-notebooks/blob/master/callysto-notebook-banner-top.jpg?raw=true)", "\n", "\n", "<a href=\"https://hub.callysto.ca/jupyter/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fcallysto%2Fcallysto-sample-notebooks&branch=master&subPath=notebooks/Digital_Citizenship/PATScores_No_Map.ipynb&depth=1\" target=\"_parent\"><img src=\"https://raw.githubusercontent.com/callysto/curriculum-notebooks/master/open-in-callysto-button.svg?sanitize=true\" width=\"123\" height=\"24\" alt=\"Open in Callysto\"/></a>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%html\n", "\n", "<script>\n", "  function code_toggle() {\n", "    if (code_shown){\n", "      $('div.input').hide('500');\n", "      $('#toggleButton').val('Show Code')\n", "    } else {\n", "      $('div.input').show('500');\n", "      $('#toggleButton').val('Hide Code')\n", "    }\n", "    code_shown = !code_shown\n", "  }\n", "  \n", "  $( document ).ready(function(){\n", "    code_shown=false;\n", "    $('div.input').hide()\n", "  });\n", "</script>\n", "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%javascript\n", "IPython.OutputArea.prototype._should_scroll = function(lines) {\n", "    return false;\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Provincial Achievement Test Scores\n", "\n", "## Introduction\n", "\n", "TODO: Improve discussion and add quantitative results if there's interest in this notebook to do that. \n", "\n", "Every year, the province of Alberta runs standardized testing for grades 6 and 9 for primary courses under the blanket identifier of Provincial Achievement Tests in order to assess how well the students preform. The results of these test are open source and readily downloaded from the Alberta Education website. In this notebook we're going to download and manipulate the data direct from Alberta education, and see if we can easily identify under and over performing school districts. Time permitting, we might even toss these onto a map using another open data set from Alberta education which contains the addresses of every school in Alberta. Using this data in combination with the provincial testing scores, we will likely be able to easily identify which school districts/schools are performing best and worst.  \n", "\n", "## Wrangling the data\n", "\n", "First let's download the data directly from the Alberta Education website and toss it in a Pandas data frame"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from numpy import nan as Nan\n", "\n", "\n", "df_ero = pd.read_excel(\"https://education.alberta.ca/media/3680591/pat-multiyear-sch-list.xlsx\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["That was pretty easily done as those are hosted excel spreadsheets. So, we don't even have to save the file locally, we can toss it straight in a pandas frame."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["school_results = df_ero.copy()\n", "school_results.head(1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Let's also collect diploma exam results\n", "diploma_results = pd.read_excel('https://education.alberta.ca/media/3680580/diploma-multiyear-sch-list-annual.xlsx')\n", "diploma_results.head(3)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["diploma_results = diploma_results.rename(columns = {\"Diploma Course\":\"Course Name\"})\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Where the above data format is going to be annoying to work with in order to plot/sort some data. Instead, let's whip this data table into \"long form\" so that we can manipulate, analyze and plot this data more easily. We do this with the code below. Notice how now we have multiple duplicate entries for \"Authority Name\" and \"School Name\" columns, as well as a handy year column for each row. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import re\n", "import time\n", "schools_reshaped = school_results.copy()\n", "start = time.time()\n", "\n", "# If there's a year in the column we want to split that bad boy\n", "def splitter(string):\n", "    r = re.compile(r'\\d{4}|\\S.*$')\n", "    return r.findall(string)\n", "\n", "cols = list(schools_reshaped)[0:8]\n", "years = ['2013', '2014', '2015', '2016', '2017']\n", "\n", "# Being lazy and creating duplicate columns with a year index. It's the same \n", "# accross the board but we need them for the next step. \n", "# The key is to not respect your RAM. \n", "for year in years:\n", "    for names in cols:\n", "        schools_reshaped[str(year +\" \"+names)] = schools_reshaped[names]\n", "\n", "\n", "schools_reshaped.columns = pd.MultiIndex.from_tuples([tuple(splitter(c)) for c in schools_reshaped.columns])\n", "schools_reshaped = schools_reshaped.stack(0).reset_index(1)\n", "\n", "end = time.time()\n", "print(end - start)\n", "schools_reshaped.rename(columns={'level_1': \"Year\"}, inplace=True)\n", "#schools_reshaped[[\"School Name\", \"Course Name\", \"Sch Enrol\", \"Year\", \"Sch Writing\"]].loc[schools_reshaped['Year'] == '2013']\n", "\n", "# Sort by school name. \n", "schools_reshaped=schools_reshaped.sort_values('School Name')\n", "\n", "del schools_reshaped[\"Form\"]\n", "del schools_reshaped[\"Language\"]\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["diploma_reshaped = diploma_results.copy()\n", "cols = list(diploma_results)[0:6]\n", "years = ['2013', '2014', '2015', '2016', '2017']\n", "\n", "# Being lazy and creating duplicate columns with a year index. It's the same \n", "# accross the board but we need them for the next step. \n", "# The key is to not respect your RAM. \n", "for year in years:\n", "    for names in cols:\n", "        diploma_reshaped[str(year +\" \"+names)] = diploma_reshaped[names]\n", "\n", "\n", "diploma_reshaped.columns = pd.MultiIndex.from_tuples([tuple(splitter(c)) for c in diploma_reshaped.columns])\n", "diploma_reshaped = diploma_reshaped.stack(0).reset_index(1)\n", "\n", "end = time.time()\n", "print(end - start)\n", "diploma_reshaped.rename(columns={'level_1': \"Year\"}, inplace=True)\n", "del diploma_reshaped[\"Sch Exam Mark Acc Sig\"]\n", "del diploma_reshaped[\"Sch Exam Mark Exc Sig\"]\n", "\n", "print(list(diploma_reshaped))\n", "\n", "diploma_reshaped = diploma_reshaped.rename(columns = {\"Sch School Mark % Acc\":\"Sch % Acc of Writing\",\n", "                                                      \"Sch School Mark % Exc\": 'Sch % Exc of Writing',\n", "                                                      \"Sch Exam Mark % Exc\":\"Sch Part 1 % Exc\",\n", "                                                     \"Sch Exam Mark % Acc\":\"Sch Part 1 % Acc\"})\n", "\n", "diploma_reshaped = diploma_reshaped[[\"Year\", \n", "                                     \"Authority Name\", \n", "                                     \"Course Name\", \n", "                                     \"School Name\",\n", "                                     \"Sch % Acc of Writing\",\n", "                                    \"Sch % Exc of Writing\",\n", "                                    \"Sch Part 1 % Exc\",\n", "                                    \"Sch Part 1 % Acc\"]]\n", "# Sort by school name. \n", "#diploma_reshaped=diploma_reshaped.sort_values('School Name')\n", "diploma_reshaped.head(1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Excellent. Now that the data have been reshaped into a \"long form\" they'll be a lot easier to work with when it comes to plotting and analysis. So, let's start to get an idea at the score distributions between schools and districts by using this dataframe as a back end to an interactive widget."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Interactive Graph\n", "\n", "Before we start any more \"involved\" analysis let's take a moment to plot these data by year to get an idea of what we're working with. In the widget below `_type` controls whether we're looking at individual schools or the school authority, `name` is the name of the school/authority, `subject` changes the subject, and `name2` is optional and will display another school/authority to compare with. Note that switching to school is a little slower, as that data set requires some set up before we can put it nicely into the widget. Also note that not all subjects are offered in each school, and they're filtered down buy what subjects were offered in the school/authority under `name`. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%matplotlib inline\n", "import matplotlib as mpl\n", "import matplotlib.pyplot as plt\n", "from plotly.offline import init_notebook_mode, iplot\n", "import plotly.graph_objs as go\n", "from ipywidgets import interact\n", "init_notebook_mode(connected=True)\n", "from ipywidgets import Dropdown\n", "\n", "schools_reshaped = pd.merge(schools_reshaped, diploma_reshaped, on = [\"Year\", \n", "                                     \"Course Name\", \n", "                                     \"School Name\",\n", "                                     \"Authority Name\", \n", "                                     \"Sch % Acc of Writing\",\n", "                                     \"Sch % Exc of Writing\",\n", "                                     \"Sch Part 1 % Acc\",\n", "                                     \"Sch Part 1 % Exc\"], how = 'outer')\n", "#schools_reshaped[schools_reshaped[\"Course Name\"] == \"Biology 30\"]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Now let's do the same with school districts\n", "# print(list(schools_reshaped))\n", "\n", "def traces(name, subject, school_or_auth):\n", "    result = None\n", "    divisor = None\n", "    y = None\n", "    y2 = None\n", "    y3 = None\n", "    if school_or_auth == \"Authority Name\":\n", "        result = schools_reshaped[schools_reshaped[school_or_auth] == name]\n", "        divisor = result.groupby(\"Year\")['Sch Enrol'].sum() - result.groupby(\"Year\")[\"Sch Absent\"].sum()    \n", "        y =  100 * (result.groupby(\"Year\")[\"Sch Acc\"].sum() - result.groupby(\"Year\")[\"Sch Exc\"].sum() )/divisor\n", "        y2 = 100 * result.groupby(\"Year\")['Sch Exc'].sum()/divisor\n", "        y3 = 100 * result.groupby(\"Year\")['Sch Below'].sum()/divisor\n", "    \n", "    if school_or_auth == \"School Name\":\n", "        result = schools_reshaped[schools_reshaped[school_or_auth] == name]\n", "        divisor = result['Sch Writing']\n", "        y = (result['Sch % Acc of Writing']-result['Sch % Exc of Writing'])# - result['Sch Exc']) / divisor\n", "        y2 = result['Sch % Exc of Writing'] #/ divisor\n", "        y3 =  result['Sch % Below of Writing']# / divisor \n", "        \n", "    result = result[result['Course Name'] == subject]\n", "\n", "    trace1 = go.Bar(x=result['Year'], y=y,\n", "                    name=\" \".join([name, '% at or above acceptable standard']))#, \n", "               \n", "    trace2 = go.Bar(x=result['Year'],\n", "                    y=y2,\n", "                    name= \" \".join([name, '% achieved a standard of excellence']))#,\n", "                \n", "    trace3 = go.Bar(x=result['Year'], \n", "                    y=y3, \n", "                    name = \" \".join([name,\"% below acceptable standard\"]))#,\n", "     \n", "    return [trace1, trace2, trace3]\n", "\n", "\n", "\n", "def compare_results( _type, name, subject, name2 = []):\n", "    \n", "    print(name, subject, _type)\n", "    \n", "    data = traces(name, subject, _type)\n", "    \n", "    if name2: \n", "        data2 = traces(name2, subject, _type)\n", "        data = data + data2\n", "    \n", "    layout = go.Layout(title=subject,\n", "                xaxis=dict(title='Year'),\n", "                yaxis=dict(title='Percentage',\n", "                      range = [0,100])\n", "                      )\n", "    \n", " \n", "    fig = go.Figure(data=data, layout=layout)\n", "    iplot(fig)\n", "\n", "    \n", "def course_drop(_type, name):\n", "    courses = list(schools_reshaped['Course Name'].unique())\n", "    filtered_course_list = []\n", "   \n", "    for course in courses:\n", "        result = schools_reshaped[schools_reshaped[_type] == name]\n", "        result = result[result['Course Name'] == course]\n", "        if _type == \"School Name\":\n", "            y = result['Sch % Acc of Writing']\n", "       \n", "        if _type == \"Authority Name\":\n", "           y = result.groupby(\"Year\")[\"Sch Acc\"].sum() - result.groupby(\"Year\")[\"Sch Exc\"].sum()\n", "            \n", "        if y.isnull().sum() > 4 or y.empty == True:\n", "            # No course for school, do nothing\n", "            #filtered_course_list.append(course)\n", "           \n", "            continue\n", "        else:\n", "            # if something exists, we'll count ita\n", "            filtered_course_list.append(course)\n", "            \n", "    if len(filtered_course_list) == 0:\n", "        # TODO: make an empty thing instead of pretending they do math\n", "        filtered_course_list.append(\"Mathematics 6\")\n", "    return filtered_course_list\n", "\n", "course_widget = Dropdown()\n", "\n", "type_widget = Dropdown(options = [\"School Name\", \"Authority Name\"], value = \"School Name\")\n", "\n", "name_widget = Dropdown()\n", "name_widget2 = Dropdown()\n", "\n", "    \n", "def update2(*args):\n", "    a = sorted(list(map(str, list(schools_reshaped[type_widget.value].unique()))))\n", "    name_widget.options = a\n", "    name_widget2.options =  a\n", "    name_widget2.value = None\n", "    # course_widget.options = course_drop(type_widget.value, x_widget.value)\n", "    name_widget.value = a[0]\n", "    \n", "\n", "    \n", "def update(*args):\n", "    course_widget.options = course_drop(type_widget.value, name_widget.value)\n", "\n", "name_widget.observe(update)  \n", "#type_widget.observe(update)\n", "type_widget.observe(update2)\n", "\n", "\n", "\n", "interact(compare_results, \n", "        _type = type_widget,\n", "         name = name_widget,\n", "         subject =  course_widget,\n", "         name2 = name_widget2\n", "        )\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Fantastic. Now we can compare which schools do well and which do poorly and in what subject. I note that the first school/authority `name` is used to filter out subjects that they don't have data for. That means that you might not see all their choices if youre using them in `name2`. I also note that if a school/authority has no test scores, then it defauls to a blank grid for mathematics 9. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## How Do Differences in Funding Affect Student Performance? \n", "\n", "The code below assumes you've downloaded all the PDFs off of the Alberta education site containing funding information from each district. If you don't have it you can either download those pdfs yourself (not recommended) or get them from our swift container `callysto-open-data` called `district_funding.csv`, of course, it is downloading it directly from swift for you. \n", "\n", "\n", "Most of the code below is just wrangling data and making plots of that data. However, what we're doing is gathering all our funding data, combining it with our data frames and then plotting it. What we'll then have is the performance of each district against the provincial average in terms of test scores for each ear and subject, as well as a graph of how those test scores were affected by differences in _total_ funding. In order to do that, we plot the density of funding and performance grades for the entire province, and then fit a line to it in order to judge positive/negative coorelation between funding and grade performance. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "\n", "# If you don't have the LAT LONG data, uncomment the line below and run this cell .\n", "temp_df = schools_reshaped.copy()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def convert(x):\n", "    try:\n", "        return x.astype(int)\n", "    except:\n", "        return x\n", "   \n", "\n", "def get_funding_data(paths = \"FundingPdf/*.pdf\"):\n", "    from tika import parser\n", "    import requests\n", "    import glob\n", "    import re\n", "    data = []\n", "    count = 0\n", "    for file in glob.iglob(paths):\n", "        parsedPDF = parser.from_file(file)\n", "    \n", "        name = file.split(\"/\")[-1]\n", "        name = name.replace(\".pdf\", \"\")\n", "        name = name.replace(\"-\", \" \").title()\n", "        name = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", name)\n", "        try:\n", "            name = name.replace(\" No \", \" No. \")\n", "        except:\n", "            pass\n", "\n", "        try: \n", "            name = name.replace(\" Ltd\", \" Ltd. \")\n", "        except:\n", "            pass\n", "\n", "        name = name.strip()\n", "\n", "        estimated_funding = None\n", "        projected_funding =  None\n", "        estimated_enroll =  None\n", "        projected_enroll =  None\n", "        year = None\n", "    \n", "        for line in parsedPDF['content'].split('\\n')[::-1]:\n", "\n", "            if \"TOTAL FUNDING\" in line:\n", "                estimate_funding = line.split()[2].replace('$',\"\").replace(\",\",\"\")\n", "                projected_funding = line.split()[3].replace('$',\"\").replace(\",\",\"\")\n", "        \n", "            if \"As of \" in line:\n", "          \n", "                try:\n", "                    print(int(line.split()[-1]))\n", "                    year = line.split()[-1]\n", "                except:\n", "                    pass\n", "        \n", "            if \"Funded Enrolment for Grades 1 - 12\" in line:\n", "           \n", "                estimated_enroll = line.split()[7].replace(\",\", \"\")\n", "                projected_enroll = line.split()[9].replace(\",\", \"\")\n", "            elif \"Enrolment for Grades 1 - 12\" in line:\n", "           \n", "                estimated_enroll = line.split()[6].replace(\",\", \"\")\n", "                projected_enroll = line.split()[8].replace(\",\", \"\")\n", "\n", "\n", "\n", "        data.append([name, estimate_funding, projected_funding, estimated_enroll, projected_enroll, year])\n", "   \n", "\n", "    df = pd.DataFrame(data, columns = [\"Authority Name\", \"Estimated Funding\", \"Projected Funding\", \"Estimated 1-12\", \"Projected 1-12\",\"Year\"])\n", "    df.to_csv(\"district_funding.csv\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "\n", "# Add district funding \n", "try: \n", "    funding = pd.read_csv(\"https://swift-yeg.cloud.cybera.ca:8080/v1/AUTH_233e84cd313945c992b4b585f7b9125d/callysto-open-data/district_funding.csv\")\n", "    del funding[\"Unnamed: 0\"]\n", "except:\n", "    get_funding_data()\n", "    \n", "    \n", "# This is to fix a pandas \"gotcha\" concerning integer arrays and NaN types. \n", "# (as in it doesn't handle it and converts to float) \n", "\n", "funding[\"Year\"] = np.nan_to_num(funding[\"Year\"]).astype(int)\n", "funding[\"Estimated 1-12\"] = np.nan_to_num(funding[\"Estimated 1-12\"]).astype(int)\n", "funding[\"Projected 1-12\"] = np.nan_to_num(funding[\"Projected 1-12\"]).astype(int)\n", "# Don't need this year's data. \n", "funding = funding[funding.Year != 2018]\n", "#funding = funding[funding.Year != np.nan]\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "# testing = pd.merge()\n", "temp_df = schools_reshaped[[\"Authority Name\", \"School Name\"]]\n", "testing = pd.merge(funding, temp_df, how='left', on = [\"Authority Name\"]).drop_duplicates()\n", "\n", "\n", "\n", "#\n", "# There's a panda's gotcha with NaN types in integer columns so we have to\n", "# go through all this crap to deal with it. \n", "testing[\"Year\"] = np.nan_to_num(testing[\"Year\"]).astype(int)\n", "testing[\"Year\"] = np.nan_to_num(testing[\"Year\"]).astype(str)\n", "testing[\"Year\"] = testing[\"Year\"].replace('0', Nan)\n", "combined_frame = pd.merge(schools_reshaped, testing, how='left',  on=['Authority Name',\"School Name\", \"Year\"])\n", "\n", "# create funding per student. \n", "combined_frame[\"Est Fund Per Student\"] = combined_frame[\"Estimated Funding\"]/combined_frame[\"Estimated 1-12\"]\n", "combined_frame[\"Proj Fund Per Student\"] = combined_frame[\"Projected Funding\"]/combined_frame[\"Projected 1-12\"]\n", "\n", "temp_df.drop_duplicates();\n", "                     "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["density_plot_frame = combined_frame.sort_values(\"Year\").copy()# .replace(0, np.NaN)\n", "\n", "import seaborn as sns\n", "from pylab import *\n", "from matplotlib import animation\n", "import numpy.ma as ma\n", "from scipy.stats import mstats\n", "\n", "density_plot_frame[\"Acc Differential Part 1\"] = density_plot_frame['Sch % Acc of Writing'] - density_plot_frame['Sch Part 1 % Acc']\n", "density_plot_frame[\"Exc Differential Part 1\"] = density_plot_frame['Sch % Exc of Writing'] - density_plot_frame['Sch Part 1 % Exc']\n", "density_plot_frame[\"Acc Differential Part 2\"] = density_plot_frame['Sch % Acc of Writing'] - density_plot_frame['Sch Part 2 % Acc']\n", "density_plot_frame[\"Exc Differential Part 2\"] = density_plot_frame['Sch % Exc of Writing'] - density_plot_frame['Sch Part 2 % Exc']\n", "\n", "density_plot_frame = density_plot_frame.rename(columns={'Sch % Exc of Writing': 'School Grade Percentage Excellent',\n", "                        'Sch % Acc of Writing': 'School Grade Percentage Acceptable',\n", "                        'Sch % Below of Writing': 'School Grade Percentage Unacceptable',\n", "                        'Sch Part 1 % Acc':'Provincial/Diploma Exam Percent Acceptable',\n", "                        'Sch Part 2 % Acc': 'Provincial Exam Percent Acceptable, Part 2',\n", "                        'Sch Part 1 % Exc':'Provincial/Diploma Exam Percent Excellent',\n", "                        'Sch Part 2 % Exc':'Provincial Exam Percent Excellent, Part 2',\n", "                        'Acc Differential Part 1': \"Acceptable Grade Differential\",\n", "                        'Acc Differential Part 2': \"Acceptable Grade Differential, Provincial Part 2\",\n", "                        'Exc Differential Part 1': \"Excellent Grade Differential\",\n", "                        'Exc Differential Part 2': \"Excellent Grade Differential, Provincial Part 2\"})    \n", "\n", "\n", "\n", "def make_density(category, year, subject, Authority=False, filter=False):\n", "    YEARS = list(density_plot_frame[\"Year\"].unique())\n", "\n", "    x = density_plot_frame[density_plot_frame[\"Course Name\"] == subject]\n", "    grade = x[[category, \"Year\"]]\n", "    funding = x[[\"Est Fund Per Student\", \"Year\"]]\n", "    points = x[[\"Est Fund Per Student\", \"Year\", category, \"Authority Name\"]]\n", "    \n", "    if Authority:\n", "        f, ax = plt.subplots(figsize=(7, 7))\n", "        \n", "        for i, year in enumerate(YEARS):\n", "                line = points[points[\"Year\"] == year][category]\n", "                downline = line.mean() - line.std()\n", "                upline = line.mean() + line.std()\n", "                line = line.mean()\n", "                if i == 0:\n", "                    label = \"Provincial Mean\"\n", "                    label1= \"Provincial 1sd\"\n", "                    \n", "                else:\n", "                    label = \"\"\n", "                    label1 = \"\"\n", "                plt.axhline(y=line,xmin= (i+.1)/(len(YEARS)),\n", "                            xmax = (i+1-.1)/(len(YEARS)), \n", "                            c=\"g\", \n", "                            label = label)\n", "                plt.axhline(y=downline,xmin= (i+.1)/(len(YEARS)), \n", "                            xmax = (i+1-.1)/(len(YEARS)), \n", "                            c=\"purple\",\n", "                            label = label1)\n", "                plt.axhline(y=upline,\n", "                            xmin= (i+.1)/(len(YEARS)),\n", "                            xmax = (i+1-.1)/(len(YEARS)), \n", "                            c=\"purple\", \n", "                            label = \"\")\n", "       \n", "        plt.style.use('ggplot')\n", "        points = points[points[\"Authority Name\"] == Authority]\n", "        grade = grade.dropna()\n", "        dd = pd.melt(points[[\"Year\", category]], id_vars = [\"Year\"], var_name = [category])\n", "        title = ''.join([Authority, \"\\n\", subject])\n", "        \n", "        try:\n", "            sns.boxplot(x=\"Year\", y=\"value\", data=dd, hue=category)\n", "            sns.swarmplot(x=\"Year\", y=\"value\", data=dd, color=\"0.25\")\n", "        except:\n", "            title = ''.join([Authority, \"\\n\", subject,\" No data\"])\n", "        plt.title(title)\n", "\n", "    else: \n", "        f, (ax1, ax2) = plt.subplots(2, figsize=(9, 9))\n", "        plt.tight_layout(pad=4)\n", "       # plt.subplot(2,1,1)\n", "        points = points.dropna()\n", "        if year:\n", "            x = points[points[\"Year\"] == year][category]\n", "            y = points[points[\"Year\"] == year][\"Est Fund Per Student\"]\n", "            if filter:\n", "                t_f = points[points[\"Year\"] == year][[category, \"Est Fund Per Student\"]]\n", "            \n", "        else:\n", "            x = points[category]\n", "            y = points[\"Est Fund Per Student\"]\n", "            if filter:\n", "                t_f = points[[category, \"Est Fund Per Student\"]]\n", "            \n", "\n", "        x1 = x.quantile(0.25)\n", "        x2 = x.quantile(0.75)\n", "        y1 = y.quantile(0.25)\n", "        y2 = y.quantile(0.75)\n", "        \n", "        ax1.plot([x1,x1], [y1,y2], c ='r', label = \"Box contains\\n50% of data\")\n", "        ax1.plot([x1,x2], [y1,y1], c='r')\n", "        ax1.plot([x1,x2], [y2,y2], c='r')\n", "        ax1.plot([x2,x2], [y1,y2], c='r')\n", "        \n", "        \n", "        try:\n", "            # To get an idea for the trend I\"m plotting al ine. \n", "            # That said these errors are likely VERY non guassian\n", "            # I don't feel like plotting them -- too deep in rabbit hole\n", "            # to go down another. SO keep in mind these are \"trends\"\n", "            # and shouldn't be read into beyond a positive/negative \n", "            # correlation. \n", "       \n", "            if filter:\n", "                # Filter outliers by one stadard dev. (VERY AGRESSIVE) \n", "                top1 = t_f[category].mean() + t_f[category].std()\n", "                top2 = t_f[\"Est Fund Per Student\"].mean() + t_f[\"Est Fund Per Student\"].std()\n", "                bottom1 = t_f[category].mean() - t_f[category].std()\n", "                bottom2 = t_f[\"Est Fund Per Student\"].mean() - t_f[\"Est Fund Per Student\"].std()\n", "                t_f = t_f[t_f[category] < top1]\n", "                t_f = t_f[t_f[category] > bottom1]\n", "                tf = t_f[t_f[\"Est Fund Per Student\"] < top2]\n", "                tf = t_f[t_f[\"Est Fund Per Student\"] > bottom2]\n", "\n", "                x = tf[category]\n", "                y = tf[\"Est Fund Per Student\"]\n", "           \n", "            limits = x\n", "            fit, V = np.polyfit(x, y, deg=1, cov=True)\n", "            \n", "            # 62 percentile. Though probably not really \n", "            # as this calculation requires the errors to be normally distributed.\n", "            error = 2*np.sqrt(np.diag(V))\n", "\n", "            label = ''.join([\"Line of best fit\\n\", \n", "                            str(round(fit[0],2)), \n", "                            \"\u00b1\",\n", "                            str(round(error[0])),\n", "                            \"x + \",\n", "                            str(round(fit[1],2)), \n", "                            \"\u00b1\",\n", "                            str(round(error[1],2))])\n", "            \n", "            ax1.plot(limits, fit[0] * limits + fit[1], \n", "                     color='purple', \n", "                     label = label)\n", "            ax1.plot(limits, \n", "                     (fit[0]+ error[0]) * limits + fit[1] + error[1], \n", "                     color = 'orange',\n", "                    label = \"\")\n", "            ax1.plot(limits, \n", "                     (fit[0]- error[0]) * limits + fit[1] - error[1],\n", "                     color = 'orange',\n", "                    label = \"\")\n", "            \n", "            test = fit[0] * x + fit[1]\n", "            residual = y - test\n", "            \n", "        # Naked exception because I'm a rule breaker. \n", "        except Exception as e:\n", "            print(\"No data available for\", subject, category)\n", "            return\n", "        \n", "        \n", "        if subject:\n", "            pass\n", "        else:\n", "            subject = \"All\"\n", "        \n", "        title = \"\".join([\"All Districts\" ,\n", "                 \"\\nMean Funding = \\$\", \n", "                 str(round(y.mean(),2)),\n", "                 \" $\\pm$ \",\n", "                str(round(y.std(), 2)),\n", "                         \" (1sd)\"\n", "                \"\\nMean Percent = \",\n", "                str(round(x.mean(),2)),\n", "                 \" $\\pm$ \",\n", "                str(round(x.std(), 2)),\n", "                \" % (1sd)\",\n", "                \"\\nSubject: \",\n", "                 subject,\n", "                        '\\n', category])\n", "        \n", "        ax1.set_title(title)\n", "        ax1.legend()\n", "        \n", "        sns.kdeplot(x, y, shade=True, ax=ax1)\n", "        \n", "        ax2.set_title(\"Distribution of Residuals of Line of Best Fit\")\n", "        \n", "        # Test if the residual is normally distributed to judge our LOBF\n", "        z,pval = mstats.normaltest(residual)\n", "        if pval < 0.05:\n", "            text = \"Errors probably not normally distributed\\n(Line of best fit shows approximate correlation only)\" \n", "        else:\n", "            # don't think this will ever happen\n", "            text = \"Errors probably normally distributed\\n(Line of best fit can be used to extrapolate)\"\n", "        \n", "        ax2.set_xlabel(\"Distance from LOBF\")\n", "        ax2.set_ylabel(\"Counts\")\n", "        ax2.hist(residual, bins = 20, histtype='bar', ec='black', label = text)\n", "        ax2.legend()\n", "    # plt.show()\n", "    \n", "    \n", "# this is a lazy copy-pase reformat of my filter function. I should probably ahve\n", "# just written a better function originally .\n", "        \n", "def course_drop2(_type, name):\n", "    \n", "    courses = list(density_plot_frame['Course Name'].unique())\n", "    for course in courses:\n", "        if \"\\n\" in course:\n", "            courses.remove(course)\n", "    \n", "    if not name:\n", "        return courses\n", "    \n", "    filtered_course_list = []\n", "   \n", "    for course in courses:\n", "        result = pd.DataFrame()\n", "        y = pd.DataFrame()\n", "        result = density_plot_frame[density_plot_frame[_type] == name].copy()\n", "        result = result[result['Course Name'] == course].copy()\n", "        if _type == \"School Name\":\n", "            y = result['School Grade Percentage Acceptable']\n", "       \n", "        if _type == \"Authority Name\":\n", "            y = result[\"School Grade Percentage Acceptable\"].copy()\n", "            \n", "        if y.isnull().sum() >= len(y) - 2 or y.empty == True:\n", "            continue\n", "        else:\n", "            # if something exists, we'll count it\n", "            filtered_course_list.append(course)\n", "            \n", "    if len(filtered_course_list) == 0:\n", "        # TODO: make an empty thing instead of pretending they do math\n", "        filtered_course_list.append(\"Mathematics 6\")\n", "    return sorted(filtered_course_list)    \n", "        \n", "    \n", "categories = ['School Grade Percentage Excellent',\n", "                     'School Grade Percentage Acceptable',\n", "                     'School Grade Percentage Unacceptable',\n", "                     'Provincial/Diploma Exam Percent Acceptable',\n", "                     'Provincial Exam Percent Acceptable, Part 2',\n", "                     'Provincial/Diploma Exam Percent Excellent',\n", "                     'Provincial Exam Percent Excellent, Part 2',\n", "                     \"Acceptable Grade Differential\",\n", "                     \"Acceptable Grade Differential, Provincial Part 2\",\n", "                     \"Excellent Grade Differential\",\n", "                     \"Excellent Grade Differential, Provincial Part 2\",\n", "                     \"School Grade Percentage Unacceptable\",\n", "                     ]\n", "Authority = [None] + sorted(map(str,list(density_plot_frame[\"Authority Name\"].unique())))\n", "\n", "auth_widget = Dropdown(options= Authority)\n", "sub_widget = Dropdown()\n", "    \n", "def update(*args):\n", "    sub_widget.options = course_drop2(\"Authority Name\", auth_widget.value)\n", "    \n", "auth_widget.observe(update)\n", "\n", "years = [None] + years\n", "\n", "\n", "\n", "interact(make_density, \n", "        category = categories,\n", "        year = years, \n", "        subject = sub_widget,\n", "        Authority = auth_widget)\n", "    \n", "    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Using the widget above you can look at the year to year and total performance of every school district as a function of funding in the top graph, and below is a histogram of the linear fit residuals. In the small chance those residuals are normally distributed, the line of best fit can be used for extrapolation. However, if they are not, the line of best fit -at best- represents approximate correlation between student performance and funding. The differential is defined as \n", "\n", "\\begin{equation}\n", "\\Delta \\text{Score} = S_{grade} - E_{grade}\n", "\\end{equation}\n", "\n", "where $S$ is the overall grade awarded by the school, and $E$ is the grade students achieved on the exam. \n", "\n", "By selecting an authority you can view the performance of that district year to year against the provincial mean as well. I note that not all authorities have exam or school marks for all courses in all years. In that case, an empty plot will be created. I also note that the provincial mean and standard deviations are also overlaying the plot, as well as individual points for each school with grades recorded. This makes it far easier to judge how well a school division performed relative to the province, as well as decide if these variations from the provincial mean are necessarily meaningful. \n", "\n", "A few interesting things to point out about the funding graph however: Excellent and acceptable scores seem to be slightly negatively correlated with funding i.e. more funding seems to be related to worse grades in some cases. That said, correlation does not depend on causation, and there are significant outliers from the actual cluster that may be over weighting the outliers. You can aggressively remove outliers by clicking the filter button which removes all points (in $x$ and $y$) that are greater than one standard deviation away from the mean of the data. I note that this feature is only available on the density plot regarding funding information.\n", "\n", "Regardless the trend is the same, and funding doesn't seem to really matter in terms of performance. If anything, more funding seems to imply that the students do worse. However, the uncertainty is so large, and the residuals are far from normal, so at best I will cautiously state that funding amount does not seem to affect overall student performance. Surely, this is likely a good sign. It may be interesting to take into account the geographic coordinates of each school and compare performance as a function of location. \n", "\n", "## Question Level Precision for Math 30-1 Wild Rose School Div. 66\n", "\n", "The province also reports the per-question performance of students on diploma exams. In this case we have the data set of the Wild Rose School Division 66 Math 30-1 scores for 2018. Below we have plotted the percentage of students who got each question correct for both the province, and the students in the Wild Rose School Division. Below we have plotted the differential defined as\n", "\n", "\\begin{equation}\n", "\\Delta \\text{Score (%)} = \\text{Score (Wild Rose) (%) } - \\text{Score (Province) (%)}\n", "\\end{equation}\n", "\n", "based on the above definition, a positive differential implies that the students of the Wild Rose School Division out performed the province, and a negative differential implies that the students under preformed in relation to the province. \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mathdf = pd.read_csv(\"math_2018_scores.csv\")\n", "del mathdf[\"instl_grp_id\"]\n", "\n", "\n", "f, xarr = plt.subplots(2,1,figsize=(20, 10))\n", "\n", "xarr[0].plot(mathdf.index, mathdf[\"prov_ms_correct_pct\"], label = \"Province\")\n", "xarr[0].plot(mathdf.index, mathdf[\"ms_correct_pct\"], label=\"Wildrose\")\n", "string = \"\".join([\"Correlation = \", \n", "                  str(round(mathdf[\"ms_correct_pct\"].corr(mathdf[\"prov_ms_correct_pct\"])*100,3)), \n", "                  \" %\"])\n", "\n", "x = np.linspace(0,39,10)\n", "\n", "up = mathdf[\"prov_ms_correct_pct\"].mean() + mathdf[\"prov_ms_correct_pct\"].std()\n", "down = mathdf[\"prov_ms_correct_pct\"].mean() - mathdf[\"prov_ms_correct_pct\"].std()\n", "up1 = mathdf[\"ms_correct_pct\"].mean() + mathdf[\"ms_correct_pct\"].std()\n", "down1 = mathdf[\"ms_correct_pct\"].mean() - mathdf[\"ms_correct_pct\"].std()\n", "\n", "\n", "xarr[0].fill_between(x, up1,down1, alpha = 0.2, label = \"Wildrose 1sd Range\", color='r')\n", "xarr[0].fill_between(x, up,down, alpha = 0.2, label = \"Provincial 1sd Range\", color='b')\n", "\n", "xarr[0].set_xlim(0,39)\n", "xarr[0].text(1,20, string,size=16)\n", "xarr[0].legend()\n", "xarr[0].set_xlabel(\"Question\", size =20)\n", "xarr[0].set_ylabel(\"Correct (%)\", size =20)\n", "\n", "up3 = (mathdf[\"ms_correct_pct\"]-mathdf[\"prov_ms_correct_pct\"]).mean() + (mathdf[\"ms_correct_pct\"]-mathdf[\"prov_ms_correct_pct\"]).std()\n", "\n", "down3 = (mathdf[\"ms_correct_pct\"]-mathdf[\"prov_ms_correct_pct\"]).mean()-(mathdf[\"ms_correct_pct\"]-mathdf[\"prov_ms_correct_pct\"]).std()\n", "\n", "xarr[1].fill_between(x, up3,down3, alpha = 0.4, label = \"1sd Range\")\n", "\n", "xarr[1].plot(mathdf.index, mathdf[\"ms_correct_pct\"]-mathdf[\"prov_ms_correct_pct\"])\n", "\n", "xarr[1].set_xlabel(\"Question\", size =20)\n", "xarr[1].set_ylabel(\"Correct Differential (%)\", size =20)\n", "xarr[1].legend()\n", "xarr[1].set_xlim(0,39)\n", "\n", "\n", "xarr[0].legend()\n", "\n", "plt.show()\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["From the plot above we see the per-question performance of Wild Rose School Division No 66. as compared to to the per-question performance of the province on the Mathematics 30-1 Diploma exam. I note that without access to the non-aggregated provincial score data it is impossible to tell if any of the variations on performance between the school division and province are statistically significant or not. In attempt to estimate this, the range defined by the first standard deviation of these data are plotted as translucent bars on these data to help identify potential outliers, and if any variations between the school division and the province are significant. However, with this small set of data, I would be hard pressed to believe that there's any variations of particular significance. The only data point that jumps out is the poor performance on question 12 by the division. Certainly however, the province did poorly on that question as well. \n", "\n", "\n", "What can be stated with certainty is that based on the correlation between  Wild Rose School Division and the province is that students in the division seemed to have trouble/do well on similar questions to the rest of the province. Beyond that however, besides providing some insights into the performance by students on each question, I'm not convinced there's any broad sweeping conclusions that can be made from this data set alone. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Performance By Question Type\n", "\n", "This can also be broken down by question type, in this case the key to the $x$ axis of each plot is as follows\n", "\n", "| Symbol  | C | P | PS | RF | TRIG | PCBT |\n", "|---------|---|---|----|----|------|------|\n", "| **Meaning** | Conceptual  |  Procedural |  Problem Solving  | Relations and Functions   |  Trigonometry   |    Permutations, Combinations and Binomial Theorem   |\n", "\n", "Below shows the performance of the province, the wild rose school district, and the differntial of performance between the Wild Rose School District and the province on each question type. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["f, xarr = plt.subplots(2,3,figsize=(20, 10))\n", "\n", "sns.boxplot(x=mathdf[\"Cognitive Level\"],y=mathdf[\"ms_correct_pct\"],ax=xarr[0,0])\n", "sns.swarmplot(x=mathdf[\"Cognitive Level\"],y=mathdf[\"ms_correct_pct\"],ax=xarr[0,0],color=\".25\")\n", "xarr[0,0].set_ylim(0,100)\n", "\n", "sns.boxplot(x=mathdf[\"Cognitive Level\"],y=mathdf[\"prov_ms_correct_pct\"], ax=xarr[0,1])\n", "sns.swarmplot(x=mathdf[\"Cognitive Level\"],y=mathdf[\"prov_ms_correct_pct\"], ax=xarr[0,1],color=\".25\")\n", "xarr[0,1].set_ylim(0,100)\n", "\n", "sns.boxplot(x=mathdf[\"Cognitive Level\"],y=mathdf[\"ms_correct_pct\"]-mathdf[\"prov_ms_correct_pct\"], ax=xarr[0,2])\n", "sns.swarmplot(x=mathdf[\"Cognitive Level\"],y=mathdf[\"ms_correct_pct\"]-mathdf[\"prov_ms_correct_pct\"], ax=xarr[0,2],color=\".25\")\n", "xarr[0,2].set_ylim(-40,40)\n", "\n", "sns.boxplot(x=mathdf[\"Topic\"],y=mathdf[\"ms_correct_pct\"],ax=xarr[1,0])\n", "sns.swarmplot(x=mathdf[\"Topic\"],y=mathdf[\"ms_correct_pct\"],ax=xarr[1,0],color=\".25\")\n", "xarr[1,0].set_ylim(0,100)\n", "\n", "sns.boxplot(x=mathdf[\"Topic\"],y=mathdf[\"prov_ms_correct_pct\"], ax=xarr[1,1])\n", "sns.swarmplot(x=mathdf[\"Topic\"],y=mathdf[\"prov_ms_correct_pct\"], ax=xarr[1,1],color=\".25\")\n", "xarr[1,1].set_ylim(0,100)\n", "\n", "sns.boxplot(x=mathdf[\"Topic\"],y=mathdf[\"ms_correct_pct\"]-mathdf[\"prov_ms_correct_pct\"], ax=xarr[1,2])\n", "sns.swarmplot(x=mathdf[\"Topic\"],y=mathdf[\"ms_correct_pct\"]-mathdf[\"prov_ms_correct_pct\"], ax=xarr[1,2],color=\".25\")\n", "xarr[1,2].set_ylim(-40,40)\n", "\n", "xarr[0,0].set_xlabel(\"Cognitive Level\", fontsize=16)\n", "xarr[0,1].set_xlabel(\"Cognitive Level\", fontsize=16)\n", "xarr[0,2].set_xlabel(\"Cognitive Level\", fontsize=16)\n", "\n", "xarr[0,0].set_ylabel(\"Provincial Question Score (%)\", fontsize=16)\n", "xarr[0,1].set_ylabel(\"District Question Score (%)\", fontsize=16)\n", "xarr[0,2].set_ylabel(\"Differential Question Score (%)\", fontsize=16)\n", "\n", "xarr[1,0].set_xlabel(\"Topic\", fontsize=16)\n", "xarr[1,1].set_xlabel(\"Topic\", fontsize=16)\n", "xarr[1,2].set_xlabel(\"Topic\", fontsize=16)\n", "\n", "xarr[1,0].set_ylabel(\"Provincial Question Score (%)\", fontsize=16)\n", "xarr[1,1].set_ylabel(\"District Question Score (%)\", fontsize=16)\n", "xarr[1,2].set_ylabel(\"Differential Question Score (%)\", fontsize=16)\n", "plt.show()\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The plots above show the performance of the province and the division based on each question type. From this there's potentially more interesting conclusions than the data set before in that the entire province, as well as the district seems to do poorly at both problem solving, and permutations combinations and binomial theorem as compared to the other categories. If there is any conclusions to take away from the above, it is that the Wild Rose School division sees its most negative differentials with relations and functions, as well as conceptual questions. \n", "\n", "## Conclusion\n", "\n", "Unfortunately there's not many concrete conclusions to take away from this data without specialized insight into the differences between divisions and individual schools. However, we did see that funding per-student does not seem to influence student performance in any significant manner. The only place there _may_ be a correlation between funding and test scores, is that students with more funding tend to do more poorly on exams. Beyond that, with the question-level resolution on the Math 30-1 diploma scores with the Wild Rose School Division we see that that division is, more or less, on par with the province with a few outliers in regards to test scores. However, students at the Wild Rose School Division seemed to have the greatest trouble with relations of functions, and conceptual questions. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["[![Callysto.ca License](https://github.com/callysto/curriculum-notebooks/blob/master/callysto-notebook-banner-bottom.jpg?raw=true)](https://github.com/callysto/curriculum-notebooks/blob/master/LICENSE.md)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.6"}}, "nbformat": 4, "nbformat_minor": 2}